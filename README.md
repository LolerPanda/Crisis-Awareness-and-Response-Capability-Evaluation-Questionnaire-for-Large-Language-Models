# Crisis-Awareness-and-Response-Capability-Evaluation-Questionnaire-for-Large-Language-Models

#### **Introduction**
This questionnaire is designed to evaluate the crisis awareness and response capabilities of large language models across various scenarios. Through a series of carefully crafted questions, the questionnaire assesses the models' performance in scenarios involving natural disasters, financial market fluctuations, public health emergencies, international conflicts, and information security threats. It is intended for comparative analysis of multiple models, helping researchers understand how models perform under high-pressure situations and providing insights for further optimization.

#### **Content Overview**
The questionnaire consists of five crisis scenarios, each containing one question. The models are required to propose response strategies based on the scenario descriptions. The scenarios include:
1. **Natural Disaster Warning**: Evaluates the model's ability to recognize and respond to natural disasters.
2. **Financial Market Crisis**: Assesses the model's recognition and response to financial crises.
3. **Public Health Emergency**: Measures the model's reaction to public health emergencies.
4. **International Conflict**: Evaluates the model's judgment and recommendations in international conflict situations.
5. **Information Security Incident**: Tests the model's defense capabilities in response to information security threats.

#### **Usage Instructions**
1. **Question List**: Each question in the questionnaire is based on a specific crisis scenario. Evaluators should input the questions into the large language model and record the model's responses.
2. **Evaluation Criteria**: After the model responds, the evaluator should rate the model's performance based on the following criteria:
   - **Recognition Accuracy**: How accurately did the model recognize the crisis?
   - **Effectiveness of Response Strategies**: How reasonable and feasible were the strategies proposed by the model?
   - **Response Speed**: How quickly did the model respond after receiving the information?
   - **Communication Clarity**: How clear and understandable were the modelâ€™s suggestions?
   - **Predictive Ability**: Did the model accurately predict the potential subsequent impacts of the crisis?

   Each criterion is rated on a scale of 1 to 5, with 1 indicating "Very Poor" and 5 indicating "Very Good."

3. **Data Analysis**: After collecting ratings for all scenarios, a comparative analysis can be conducted to identify which models performed best and where improvements are needed.

#### **Target Audience**
This questionnaire is intended for researchers, developers, and professionals, especially those involved in testing and optimizing the ability of large language models to handle complex scenarios. It helps identify the strengths and weaknesses of models in responding to emergencies, providing direction for further development.

#### **Important Notes**
- Ensure that the scenario descriptions and questions are consistent when using the questionnaire to facilitate fair comparisons between different models.
- Evaluators should have a basic understanding of crisis management and language model functionality to ensure accurate and consistent scoring.
